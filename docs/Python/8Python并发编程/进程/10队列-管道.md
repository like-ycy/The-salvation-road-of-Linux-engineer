# 进程间的通信（管道和队列）

我们知道进程之间数据是相互隔离的，要想实现进程间的通信(IPC机制)，就必须借助于一些技术才可以。比如multiprocessing模块中的：队列和管道，这两种方式都是可以实现进程间数据传输的，由于队列是管道+锁的方式实现，所以我们着重研究队列即可

## 管道

+ 导入

  ```python
  from multiprocessing import Pipe
  ```

+ 创建管道对象

  ```python
  a, b = Pipe()
  ```

+ 方法

  + send  发送数据
  + recv    接收数据

+ 实现

```python
from multiprocessing import Pipe, Process


def fun(a):
# 获取管道a
a.send(list(range(10)))
print('我在子进程接收主进程数据', a.recv())



if __name__ == '__main__':
a, b = Pipe()
p = Process(target=fun, args=(a,))
p.start()
b.send(['a', 'b', 'c'])
p.join()
# 接收数据
print('在主进程接收子进程传递数据', b.recv())
```

  


## 队列概念

创建共享的进程队列，Queue是多进程安全的队列，可以使用Queue实现多进程之间的数据传递。

大白话总结一下就是队列支持多个人从队列的一端放入数据，同样支持多个人从队列的另一端取数据

### 基本用法

#### 1、导入

```python
from multiprocessing import Queue
```

#### 2、参数

```
Queue([maxsize]) # 创建共享的进程队列 队列底层使用管道和锁定实现。
```

maxsize是队列中允许的最大项数。如果省略此参数，则无大小限制。

#### 3、常用方法

`Queue([maxsize])`：创建共享的进程队列。maxsize是队列中允许的最大项数。如果省略此参数，则无大小限制。底层队列使用管道和锁定实现。另外，还需要运行支持进程以便队列中的数据传输到底层管道中。
Queue的实例q具有以下方法：

`q.get( [ block [ ,timeout ] ] )`：返回q中的一个项目。如果q为空，此方法将阻塞，直到队列中有项目可用为止。block用于控制阻塞行为，默认为True. 如果设置为False，将引发Queue.Empty异常（定义在Queue模块中）。timeout是可选超时时间，用在阻塞模式中。如果在制定的时间间隔内没有项目变为可用，将引发Queue.Empty异常。

`q.get_nowait()` ：同`q.get(False)`方法。

`q.put(item [, block [,timeout ] ] )` ：将item放入队列。如果队列已满，此方法将阻塞至有空间可用为止。block控制阻塞行为，默认为True。如果设置为False，将引发Queue.Empty异常（定义在Queue库模块中）。timeout指定在阻塞模式中等待可用空间的时间长短。超时后将引发Queue.Full异常。

`q.qsize()` ：返回队列中目前项目的正确数量。此函数的结果并不可靠，因为在返回结果和在稍后程序中使用结果之间，队列中可能添加或删除了项目。在某些系统上，此方法可能引发NotImplementedError异常。

`q.empty()` ：如果调用此方法时 q为空，返回True。如果其他进程或进程正在往队列中添加项目，结果是不可靠的。也就是说，在返回和使用结果之间，队列中可能已经加入新的项目。

`q.full()` ：如果q已满，返回为True. 由于进程的存在，结果也可能是不可靠的（参考`q.empty()`方法）。

#### 4、其他方法（了解）

`q.close()` ：关闭队列，防止队列中加入更多数据。调用此方法时，后台进程将继续写入那些已入队列但尚未写入的数据，但将在此方法完成时马上关闭。如果q被垃圾收集，将自动调用此方法。关闭队列不会在队列使用者中生成任何类型的数据结束信号或异常。例如，如果某个使用者正被阻塞在`get()`操作上，关闭生产者中的队列不会导致`get()`方法返回错误。

`q.cancel_join_thread()` ：不会再进程退出时自动连接后台进程。这可以防止`join_thread()`方法阻塞。

`q.join_thread()` ：连接队列的后台进程。此方法用于在调用`q.close()`方法后，等待所有队列项被消耗。默认情况下，此方法由不是q的原始创建者的所有进程调用。调用`q.cancel_join_thread()`方法可以禁止这种行为。

#### 5、代码实现

```python
from multiprocessing import Queue
q=Queue(3)  # 创建一个最大只能容纳3个数据的队列
"""
常用方法
put ,get ,put_nowait,get_nowait,full,empty
"""
q.put(3)  # 往队列中存放数据
q.put(3)
q.put(3)


q.put(3)  # 如果队列已经满了，程序就会停在这里，等待数据被别人取走，再将数据放入队列。如果队列中的数据一直不被取走，程序就会永远停在这里。
try:
    q.put_nowait(3) # 可以使用put_nowait，如果队列满了不会阻塞，但是会因为队列满了而报错。
except:  # 因此我们可以用一个try语句来处理这个错误。这样程序不会一直阻塞下去，但是会丢掉这个消息。
    print('队列已经满了')
    

# 因此，我们再放入数据之前，可以先看一下队列的状态，如果已经满了，就不继续put了。
print(q.full())  # 判断队列中数据是否已存放满了

print(q.get())  # 从队列中获取数据
print(q.get())
print(q.get())


print(q.get()) # 同put方法一样，如果队列已经空了，那么继续取就会出现阻塞。
try:
    q.get_nowait(3) # 可以使用get_nowait，如果队列满了不会阻塞，但是会因为没取到值而报错。
except: # 因此我们可以用一个try语句来处理这个错误。这样程序不会一直阻塞下去。
    print('队列已经空了')

    
print(q.empty())  # 判断队列中数据是否已经被全部取出
```

### 基于队列实现进程间通信

```python
import time
from multiprocessing import Process, Queue
def f(q):
    q.put('hello')  #调用主函数中p进程传递过来的进程参数 put函数为向队列中添加一条数据。
if __name__ == '__main__':
    q = Queue()  # 创建一个Queue对象
    p = Process(target=f, args=(q,)) #创建一个进程
    p.start()
    print(q.get())  # 从队列中获取数据
    p.join()


from multiprocessing import Queue,Process
def producer(q):
    q.put('hello big baby!')
def consumer(q):
    print(q.get())
if __name__ == '__main__':
    q = Queue()
    p = Process(target=producer,args=(q,))
    p.start()
    p1 = Process(target=consumer,args=(q,))
    p1.start()
```

## 数据共享

+ 字典共享

  + 导入

    import multiprocessing

  + 实例化创建字典

    ```python
    import multiprocessing
    
    if __name__ == '__main__':
        multiprocessing.Manager().dict()
    ```

  + 实例

    ```python
    import multiprocessing
    
    def fun(Dict):
        Dict['x'] = 'x'
        Dict['y'] = 'y'
    
    
    if __name__ == '__main__':
        myDict = multiprocessing.Manager().dict()
        p = multiprocessing.Process(target=fun, args=(myDict,))
        p.start()
        p.join()
        print(myDict)
        print('over')
    ```

+ 列表共享

  + 导入

    import multiprocessing

  + 实例化创建列表

    ```python
    import multiprocessing
    
    if __name__ == '__main__':
        multiprocessing.Manager().list()
    ```

  + 实例

    ```python
    import multiprocessing
    
    
    def fun(my_list):
        my_list.append('x')
        my_list.append('y')
        my_list.append('z')
    
    
    if __name__ == '__main__':
        my_list = multiprocessing.Manager().list()
        p = multiprocessing.Process(target=fun, args=(my_list,))
        p.start()
        p.join()
        print(my_list)
        print('over')
    ```

## JoinableQueue的使用

**语法：**

1. 实例化对象：`q = JoinableQueue()`
2. 向队列中放入内容，相当于 信号量+1 操作: `q.put(xxx)`
3. 从队列中取出内容：`q.get()`
4. 任务结束，相当于 信号量-1 操作:`q.task_done()`
5. 当这个 信号量不为0时，会阻塞等待，计数器为0后通过。

**实例：**

```python
# JoinableQueue的使用
q = JoinableQueue()

q.put('1')  # +1
q.put('2')  # +1

print(q.get())
q.task_done()   # -1	
print(q.get())
q.task_done()  # -1
q.join() #计数器不为0会阻塞等待 计数器为0后通过
```

**通过JoinableQueue队列实现生产者消费者模型**

```python
def producer(q, name, food):
    '''生产者'''
    for i in range(10):
        print(f'{name}生产了{food}{i}')
        res = f'{food}{i}'
        q.put(res)  # +1


def consumer(q, name):
    '''消费者'''
    while 1:
        res = q.get()
        if res == None:
            break
        print(f'{name}买了{res}')
        q.task_done()


if __name__ == '__main__':
    q = JoinableQueue()     # 使用加了join的队列
    p1 = Process(target=producer, args=(q, "xc", "意大利面"))
    c1 = Process(target=consumer, args=(q, "haha"))
    p2 = Process(target=producer, args=(q, "xc", "牛肉"))
    c2 = Process(target=consumer, args=(q, "xixi"))
    p3 = Process(target=producer, args=(q, "xc", "可乐"))
    # 把消费者变成守护进程，主进程结束，子进程就结束
    c1.daemon = True    # 进程结束，子进程就结束
    c2.daemon = True    # 进程结束，子进程就结束

    p1.start()
    c1.start()
    p2.start()
    c2.start()
    p3.start()

    p1.join()  # 等待生产者结束
    p2.join()  # 等待生产者结束
    p3.join()  # 等待生产者结束
```

上述代码中，是**通过将子进程变为守护进程**，在消费者的子进程中**每次收到消息都task_done**，然后**等待主进程结束，直接结束子进程**。